To check whether there are any races, the dynamic programming model currently works with a graph composed of configurations that look like this: ((e1, e2, ..., en), (v1, v2, ..., vm)) where n is the number of threads, m is the number of variables, ei is an event index for thread i and vj is the value for variable j. Then the dynamic programming algorithm starts with the ((0, 0, ..., 0), (0, 0, ..., 0)) state and recursively expands it into all the reachable states.

This is reasonably good, but it's not necessarily better than the SMT model. Indeed, in many cases it is somehow worse.

First, let us notice that, for two threads, if t1 accesses variable v1 with i1 as the event index and t2 accesses v2 at with i1 as the index, then the algorithm has at least one state for the (i1, i2) index pair. However, this pair does not provide anything useful to the analysis. One option would be that we analyse the t1 and t2 threads separately at these indexes, but that gets complicated quickly.

A simple way to optimize this is to run threads in jumps, stopping only at lock acquire and release time. I.e. instead of having simple read/write/whatever instructions we have complex instructions made of individual read/write/whatever instructions. Other than that, the algorithm is preety much the same.

However, this does not take advantage of the (i1, i2) independence mentioned above. To use that, we will build a data structure that includes all the possible executions.

Let us say that two threads interact on a pair (i1, i2) if one of these happen:
* Both access the same data, one of them is a write and the two threads do not hold the same lock.
* Both access the same lock and one of them is a lock.
* One is a fork/start thread event and the other is a begin thread event.
* One is a join event and the other is an end thread event.
* On each thread we add an extra event before its beginning and an extra event after its end. All the before-begin events interact. All the after-end events interact.

If t, s are two threads, then we define Interactions(t, s) as all pairs (i, j) on which t and s interact.

From a discussion with Traian: We can give up on the "hold the same lock" above by considering locks/unlocks as (roughly) an atomic read+write to a variable, or something like that. While that would provide a more general framework, for the rv-predict tool it is better to treat them as mentioned above since it reduces the number of interactions that need to be taken into account.

Interaction data structure
--------------------------

Given a subset of threads T:

An index instance is any function I : T -> Nat such that I(t) is a valid index for thread t.

If I, J are two index instances then I < J if I(t) <= J(t) for all t in T and I != J.

Given a set S of index instances and an index I then Next(I, S) = {J in S | I < J and there is no K with I < K < J}. If t and s are two threads and (i, j) is a tuple in Interactions(t, s), then Next(i, j) = Next(I, Interactions(t, s)) where I:{t, s}->N is given by I(t) = i, I(s) = j.

Now let us recursively define a data structure that models interactions in a way that is useful for analysis. We will take each thread and add it to the data structure as such (any order on threads would work):

For the first thread t we build a chain I0->I1->I2->...->Iend1, with Ik:{t}->N given by Ik(t) = k. Obviously, this chain is a DAG.

For any other thread t, let Interactions(t) be the set of tuples (i, s, j) such that s is a previously processed thread and (i, j) is an interaction between event i on s ond j on t.

Let FullInteractions(t) be the set of index instances I such that:
* There is a thread s that was previously processed such that there is a tuple (I(s), s, I(t)) in Interactions(t).
* For any thread q!=s that was previously processed, there is a tuple (I(q), q, j) in Interactions(t) with j <= I(t).

The intent of these full interactions is to model that we executed thread t until we reached I(t) and, for any other thread p, the last interaction between t and p was I(p). To realize this intent, we do the following:

We start a DAG by adding the (full) interaction I0 between the before-beginning events for all the processed threads and the current one. This interaction is in the "unexpanded" state. Then, while possible, we take an unexpanded full interaction I and we expand it as such:

For any previously processed thread s, and for any (i, j) in Next(I(s), I(t)), and for any J in s's DAG with:
* J(s) = i
* J(q) >= I(q) for all q < s
* For all q < s, there is no interaction (k, l) in Next(I(q), I(t)) with (k, l) < (J(q), j)
* For all q < s, in the [I(q), J(q)) interval q does not acquire any lock that is held by any thread p with s < p <= t just before executing I(p). (TODO: Make sure that I don't need q<=s).

To resume, for any J with those properties, let us define K:{q | q <= t}->N by K(q) = J(q) for q <= s, K(q) = I(q) for s<q<t, K(t) = j. We add K to t's DAG (if it's not already there) and we link I to K.

After that, we mark I as "processed".

End of algorithm.

Given two DAG nodes I, J (can be on the same thread), they are incompatible if there are two threads p, q such that I(p)<J(p) and I(q) > J(q)
A compatible set of DAG nodes {Is} with s in S where S is a subset of nodes, is as set of nodes without any incompatible nodes in it.

Claim 1: Any node in any of the DAGs is reachable (if we ignore the compatibility between read and write events, e.g. we replace them by nop events).
Claim 2: Given any compatible set of nodes {Is} there is an execution that goes through all of them (again, ignoring r/w compatibility).
Claim 3: if I is index instance that is reachable, then we can find for each thread s two nodes Is and Js in s's DAG such that:
* There is an path Is -> Js
* Is(q) <= I(q) for q <= s
* Js(q) >= I(q) for q <= s

